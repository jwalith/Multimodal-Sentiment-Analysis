{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Multimodal Sentiment Analysis Demo\n",
        "\n",
        "This notebook demonstrates how to use the multimodal sentiment analysis system that combines CLIP image embeddings with BERT text sentiment embeddings to detect sentiment in memes, ads, and social media posts.\n",
        "\n",
        "## Overview\n",
        "\n",
        "The system consists of:\n",
        "1. **CLIP Image Embedder**: Extracts semantic features from images\n",
        "2. **BERT Text Sentiment Embedder**: Extracts sentiment-aware features from text\n",
        "3. **Multimodal Fusion Model**: Combines both embeddings using attention mechanisms\n",
        "4. **Sentiment Classifier**: Predicts sentiment (negative, neutral, positive)\n",
        "\n",
        "## Features\n",
        "- Real-time sentiment analysis\n",
        "- Support for images from URLs or local files\n",
        "- Batch processing capabilities\n",
        "- Detailed confidence scores and explanations\n",
        "- REST API for integration\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
